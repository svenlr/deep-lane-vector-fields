import numpy as np
import torch


def one_hot(label, num_classes):
    """ convert a index-encoded label image to a logits (C, H, W) tensor in numpy """
    n, m = label.shape
    logits = np.zeros((n * m, num_classes))  # empty, flat array
    logits[np.arange(n * m), label.flatten()] = 1  # one-hot encoding for 1D
    logits = logits.reshape((n, m, num_classes))  # reshaping back to 3D tensor
    # (H, W, C) to (C, H, W)
    logits = np.swapaxes(logits, 0, 2)
    logits = np.swapaxes(logits, 1, 2)
    return logits


def one_hot_torch(target, num_classes):
    """ convert a index-encoded label image to a logits (C, H, W) tensor using pytorch """
    target = target.unsqueeze(1)
    target_one_hot = torch.zeros((target.shape[0], num_classes, *target.shape[-2:]), dtype=torch.float32, device=target.device)
    ones = torch.ones(target_one_hot.size(), dtype=torch.float32, device=target.device)
    target_one_hot.scatter_(1, target, ones)
    return target_one_hot


def reverse_one_hot(image):
    """
    Transform a 2D array in one-hot format (depth is num_classes),
    to a 2D array with only 1 channel, where each pixel value is
    the classified class key.

    # Arguments
        image: The one-hot format image

    # Returns
        A 2D array with the same width and height as the input, but
        with a depth size of 1, where each pixel value is the classified
        class key.
    """
    image = image.permute(1, 2, 0)
    x = torch.argmax(image, dim=-1)
    return x


def reverse_one_hot_uint8(image):
    image = image.permute(1, 2, 0)
    x = torch.argmax(image, dim=-1).to(torch.uint8)
    return x


def compute_precision(pred, label):
    pred = pred.flatten()
    label = label.flatten()
    total = len(label)
    return (pred == label).astype(np.float).sum() / float(total)


def compute_precision_torch(pred, label):
    # type: (torch.Tensor, torch.Tensor) -> float
    pred = pred.flatten()
    label = label.flatten()
    return ((pred == label).to(torch.float32).sum() / label.numel()).cpu().numpy()


def fast_hist_torch(gt, pred, n, ignore_idx=255):
    '''
    Efficiently generate confusion matrix histograms (Bxnxn) for a given pair of prediction and ground truth batches.
    Confusions with the ignore idx in both ways are not being counted,
    which effectively means that false positive in ground truth ignore regions are not penalized by the mIoU metric.
    A perfect match should produce the identity matrix.

    These histograms can be summed across all batches in order to calculate the mean IoU with per_class_iu().

    gt and pred are ground truth and prediction respectively
    n is the number of classes
    '''
    pred = pred.clone()
    # false positives in ignore regions are not penalized
    pred[gt == ignore_idx] = ignore_idx
    histograms = []
    for batch_idx in range(pred.shape[0]):  # bin count can not be performed per batch at the moment
        gt_i = gt[batch_idx, ...]
        pred_i = gt[batch_idx, ...]
        histograms.append(torch.bincount(n * gt_i.to(torch.int32).flatten() + pred_i.to(torch.int32).flatten(), minlength=n ** 2).reshape(n, n))
    return torch.stack(histograms, dim=0)


def per_class_iu(hist):
    """
    Given the histogram generated by fast_hist_torch(), compute the intersection over union.
    Returns a list of mIoU for each class separately, also containing the ignore class if there is one.
    """
    epsilon = 1e-5
    return (np.diag(hist) + epsilon) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)
